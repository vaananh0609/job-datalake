name: Run ETL Job

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'run mode (dry-run or full)'
        required: false
        default: 'dry-run'

jobs:
  run-etl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run ETL (dry-run or full)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          S3_PREFIX: ${{ secrets.S3_PREFIX }}
        run: |
            set -e
          
            export S3_BUCKET_NAME="${S3_BUCKET_NAME}"
            export S3_PREFIX="${S3_PREFIX:-raw_data/jobs/}"
          
            if [ -z "$S3_BUCKET_NAME" ]; then
              echo "❌ S3_BUCKET_NAME is EMPTY"
              exit 1
            fi
          
            S3_PATH="s3a://${S3_BUCKET_NAME}/${S3_PREFIX}"
            echo "✅ Using S3_PATH=$S3_PATH"
          
            MODE="${{ github.event.inputs.mode }}"
          
            if [ "$MODE" = "dry-run" ]; then
              python etl_job.py \
                --s3-path "$S3_PATH" \
                --endpoint "https://s3.amazonaws.com"
            else
              python etl_job.py \
                --s3-path "$S3_PATH" \
                --endpoint "https://s3.amazonaws.com" \
                --write-output \
                --out-prefix processed
            fi
